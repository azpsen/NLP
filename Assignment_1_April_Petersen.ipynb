{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DofX4RZumFrm"
      },
      "source": [
        "### N-gram Language Model\n",
        "In this assignment, you will build several n-gram models. For submission, you will need to first ***make a copy of this notebook*** (File-> save a copy to drive). Next, fill out each of the functions for each task. Make sure to run each cell and check if the output is correct or not. Finally, submit a pdf (File->print). Note, you can not use any library for the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBGBXSwDljoX",
        "outputId": "dfdd3171-6e37-4215-9365-501a12bebf14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[',', 'i', 'can', 'mend', 'you', 'mur', '.', 'what', 'mean', \"'\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /config/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /config/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import and download corpus\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# getting a list of words from this book\n",
        "caesar = gutenberg.words('shakespeare-caesar.txt')\n",
        "# convert all to lower case\n",
        "caesar = [l.lower() for l in caesar]\n",
        "# print first ten words here\n",
        "print(caesar[210:220])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIzusZc_m8pB"
      },
      "source": [
        "#### Task 1: Write functions to count unique occurences and co-occurence. (Points: 5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "PZXUPWzIl_mR"
      },
      "outputs": [],
      "source": [
        "def count_unique_occurences(list_of_words):\n",
        "  L = []\n",
        "  # L should be a lit of tuples (a, b) where a is the word and b is the count\n",
        "  # replace the list here with your code\n",
        "\n",
        "  L = [(x, list_of_words.count(x)) for x in set(list_of_words)]\n",
        "\n",
        "  return L\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "XlEg1y05mZrA"
      },
      "outputs": [],
      "source": [
        "def count_co_occurences(list_of_words):\n",
        "  #L = []\n",
        "  # L should be a lit of tuples (a, b) where a is the word1:word2 and b is the count\n",
        "  # replace the list here with your code\n",
        "  #L = [('julius:ceasur', 5), ('i:am', 3)]\n",
        "\n",
        "  counts = {}\n",
        "\n",
        "  for i in range(len(list_of_words) - 1):\n",
        "    key = f\"{list_of_words[i]}:{list_of_words[i+1]}\"\n",
        "    if key in counts.keys():\n",
        "      counts[key] += 1\n",
        "    else:\n",
        "      counts[key] = 1\n",
        "\n",
        "  return list(counts.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPzSfWLaqWQ2",
        "outputId": "bfeeb6f8-f785-4663-abbd-3750f60a248d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('coffin', 1)\n",
            "('goe', 4)\n",
            "('signe', 4)\n",
            "('defeat', 1)\n",
            "('attyre', 1)\n"
          ]
        }
      ],
      "source": [
        "# print first five occurences\n",
        "occurences = count_unique_occurences(caesar)\n",
        "_ = [print(l) for l in occurences[:5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkk3cmSlrKZ3",
        "outputId": "85aa4086-310e-4c5f-d4c7-76921cb9badb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('[:the', 1)\n",
            "('the:tragedie', 2)\n",
            "('tragedie:of', 2)\n",
            "('of:julius', 1)\n",
            "('julius:caesar', 1)\n"
          ]
        }
      ],
      "source": [
        "# print first five co-occurences\n",
        "co_occurences = count_co_occurences(caesar)\n",
        "_ = [print(l) for l in co_occurences[:5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm2t1UTJpzbe"
      },
      "source": [
        "#### Task 2: write functions to compute unigram and bigram proability (Points: 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "Z21zVmYvpiCt"
      },
      "outputs": [],
      "source": [
        "def occurences_probability(list_of_counts):\n",
        "  L = []\n",
        "  # L should be a lit of tuples (a, b) where a is the word and b is the probability\n",
        "  # replace the list here with your code\n",
        "  #L = [('julius', '0.2'), ('ceasur', '0.8')]\n",
        "\n",
        "  total = sum(count for _, count in list_of_counts)\n",
        "\n",
        "  L = [(word, count / total) for word, count in list_of_counts]\n",
        "\n",
        "  return L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "AlX0JmKcsc1F"
      },
      "outputs": [],
      "source": [
        "def co_occurences_probability(list_of_counts):\n",
        "  L = []\n",
        "  # L should be a lit of tuples (a, b) where a is the word1:word2 and b is the probability\n",
        "  # replace the list here with your code\n",
        "\n",
        "  # Build individual word count dict from pair word counts\n",
        "  word_counts = {}\n",
        "  for pair, count in list_of_counts:\n",
        "    [a, b, *_] = pair.split(':')\n",
        "    if a in word_counts.keys():\n",
        "      word_counts[a] += count\n",
        "    else:\n",
        "      word_counts[a] = count\n",
        "  # Add very last item in pair list (won't be added in for loop)\n",
        "  last_pair, last_count = list_of_counts[-1]\n",
        "  last_pair = last_pair.split(':')\n",
        "  if last_pair[1] in word_counts.keys():\n",
        "    word_counts[last_pair[1]] += last_count\n",
        "  else:\n",
        "    word_counts[last_pair[1]] = last_count\n",
        "\n",
        "  pair_counts = dict(list_of_counts)\n",
        "\n",
        "  # Populate L with the probability of pair[1] given pair[0] for each pair\n",
        "  L = [(pair, pair_counts[pair] / word_counts[pair.split(':')[0]]) for pair, _ in list_of_counts]\n",
        "\n",
        "  return L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfGrNSsrswbt",
        "outputId": "b7198bd7-b0cb-4200-ad9a-04830205f840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('coffin', 3.871017690550846e-05)\n",
            "('goe', 0.00015484070762203383)\n",
            "('signe', 0.00015484070762203383)\n",
            "('defeat', 3.871017690550846e-05)\n",
            "('attyre', 3.871017690550846e-05)\n"
          ]
        }
      ],
      "source": [
        "# print first five occurences\n",
        "occ_prob = occurences_probability(occurences)\n",
        "_ = [print(l) for l in occ_prob[:5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOdeArJStM_7",
        "outputId": "d87ae2ad-77d7-43bc-9c59-e579ed197bf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('[:the', 0.3333333333333333)\n",
            "('the:tragedie', 0.0034542314335060447)\n",
            "('tragedie:of', 1.0)\n",
            "('of:julius', 0.002824858757062147)\n",
            "('julius:caesar', 1.0)\n"
          ]
        }
      ],
      "source": [
        "# print first five co-occurences probabilities\n",
        "co_occ_prob = co_occurences_probability(co_occurences)\n",
        "_ = [print(l) for l in co_occ_prob[:5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3DuNj8Zt-DR"
      },
      "source": [
        "#### Task 3: Find probability of a sentence using unigram and bigram model (points 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "EPIG3Ecnt5oI"
      },
      "outputs": [],
      "source": [
        "def unigram_sent_probability(sent, prob_list):\n",
        "  prob = 1\n",
        "  # compute probability\n",
        "  # here sent will be a string that you will have to split\n",
        "\n",
        "  prob_dict = dict(prob_list)\n",
        "  for word in sent.split(' '):\n",
        "    prob *= prob_dict[word]\n",
        "\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "ke0b3-XPvMCF"
      },
      "outputs": [],
      "source": [
        "def bigram_sent_probability(sent, prob_list):\n",
        "  prob = 1\n",
        "  # compute probability\n",
        "  # here sent will be a string that you will have to split\n",
        "\n",
        "  words = sent.split(' ')\n",
        "  word_pairs = []\n",
        "  for i in range(len(words) - 1):\n",
        "    word_pairs.append(words[i] + ':' + words[i + 1])\n",
        "\n",
        "  prob_dict = dict(prob_list)\n",
        "\n",
        "  for pair in word_pairs:\n",
        "    prob *= prob_dict[pair]\n",
        "\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT8pKviPvbZj",
        "outputId": "b96bc787-1521-4a01-ad72-0b94857e90cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigram probability for i can mend you is: 1.7782310416861445e-11\n",
            "Bigram probability for i can mend you is: 0.00039498370692208945\n"
          ]
        }
      ],
      "source": [
        "sent = \"i can mend you\"\n",
        "u_prob = unigram_sent_probability(sent, occ_prob)\n",
        "b_prob = bigram_sent_probability(sent, co_occ_prob)\n",
        "print(\"Unigram probability for\", sent, \"is:\", u_prob)\n",
        "print(\"Bigram probability for\", sent, \"is:\", b_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ASRMOXxA4M"
      },
      "source": [
        "#### Task 4: Predict the most probable next word (Points 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "JVqP90jOwZXa"
      },
      "outputs": [],
      "source": [
        "def uni_predict_next_words(sent, prob_list, n=1):\n",
        "  # go through all combination of words and find the next n words with highest probability and return the list\n",
        "  # replace this with your code\n",
        "  # word = ['I']\n",
        "\n",
        "  prob_list.sort(key=lambda a: a[1], reverse=True)\n",
        "\n",
        "  words = [word for word, _ in prob_list[:n]]\n",
        "  return words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "bFvJ93ns04E6"
      },
      "outputs": [],
      "source": [
        "def bi_predict_next_words(sent, prob_list, n=1):\n",
        "  # go through all combination of words and find the next n words with highest probability and return the list\n",
        "  # replace this with your code\n",
        "  # word = ['I']\n",
        "\n",
        "  words = sent.split(' ')\n",
        "  last_word = words[-1]\n",
        "  prob_given_list = []\n",
        "  for pair, prob in prob_list:\n",
        "    [first, second, *_] = pair.split(':')\n",
        "    if first == last_word:\n",
        "      prob_given_list.append((second, prob))\n",
        "\n",
        "  prob_given_list.sort(key=lambda a: a[1], reverse=True)\n",
        "\n",
        "  words = [word for word, _ in prob_given_list[:n]]\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CraaOB9gykmt",
        "outputId": "ce9ee116-491b-41d3-9f8a-837e6b2b9f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigram-based next best word for i can mend you is: [',', '.', 'and', 'the', 'i']\n",
            "Bigram-based next best word for i can mend you is: [',', 'are', 'know', 'haue', 'shall']\n"
          ]
        }
      ],
      "source": [
        "u_next_words = uni_predict_next_words(sent, occ_prob, n=5)\n",
        "b_next_words = bi_predict_next_words(sent, co_occ_prob, n=5)\n",
        "print(\"Unigram-based next best word for\", sent, \"is:\", u_next_words)\n",
        "print(\"Bigram-based next best word for\", sent, \"is:\", b_next_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2nCDjo91ZAa"
      },
      "source": [
        "#### Task 5: Interpolated Probability. (Points 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "tlszF7V0znkP"
      },
      "outputs": [],
      "source": [
        "def linearly_interpolated_sent_probability(sent, lam1, prob_list_u, lam2, prob_list_b):\n",
        "  # here instead of uni or bigram, you will use linear interpolation to find the probability of the sentence\n",
        "  # lambda values are lam1 for unigram and lam2 for bigram\n",
        "  # replace this line with your code\n",
        "\n",
        "  unigram_prob = unigram_sent_probability(sent, prob_list_u)\n",
        "  bigram_prob = bigram_sent_probability(sent, prob_list_b)\n",
        "\n",
        "  return lam1 * unigram_prob + lam2 * bigram_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "672orwHI2uew",
        "outputId": "40624f2d-0a6c-48cd-a086-d52b1ae4aead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With lamda  0.1 0.9 interpolated probability for i can mend you is: 0.0003554853380081116\n",
            "With lamda  0.2 0.8 interpolated probability for i can mend you is: 0.0003159869690941337\n",
            "With lamda  0.3 0.7 interpolated probability for i can mend you is: 0.0002764886001801557\n",
            "With lamda  0.4 0.6 interpolated probability for i can mend you is: 0.0002369902312661778\n",
            "With lamda  0.5 0.5 interpolated probability for i can mend you is: 0.00019749186235219993\n",
            "With lamda  0.6 0.4 interpolated probability for i can mend you is: 0.00015799349343822205\n",
            "With lamda  0.7 0.3 interpolated probability for i can mend you is: 0.00011849512452424414\n",
            "With lamda  0.8 0.2 interpolated probability for i can mend you is: 7.899675561026621e-05\n",
            "With lamda  0.9 0.1 interpolated probability for i can mend you is: 3.949838669628831e-05\n"
          ]
        }
      ],
      "source": [
        "# lets see how probability changes with lambda values\n",
        "for i in range(1,10):\n",
        "  l_prob = linearly_interpolated_sent_probability(sent, i/10, occ_prob, 1-(i)/10, co_occ_prob)\n",
        "  print(\"With lamda \", i/10, \"%.1f\" % (1-(i)/10), \"interpolated probability for\", sent, \"is:\", l_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEv9atKO33tJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
